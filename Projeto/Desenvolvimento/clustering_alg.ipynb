{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cluster, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice\n",
    "from one_dimensional_gaussian_kernel import OneDimensionalGaussianKernel\n",
    "from multi_dimensional_gaussian_kernel import MultiDimensionalGaussianKernel\n",
    "\n",
    "\n",
    "class Clustering_Alg:\n",
    "    def __init__(self):\n",
    "        self.datasets = []\n",
    "        self.selected_clustering_algorithms = []\n",
    "        self.clustering_algorithms = {}\n",
    "        self.clustering_variables = []\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def data_scaler(self, data):\n",
    "        temp_scaler = StandardScaler()\n",
    "        temp_scaler.mean_ = self.scaler.mean_\n",
    "        temp_scaler.var_ = self.scaler.var_\n",
    "        temp_scaler.n_samples_seen_ = self.scaler.n_samples_seen_\n",
    "        temp_scaler.scale_ = self.scaler.scale_\n",
    "        return temp_scaler.transform(data)\n",
    "\n",
    "    def set_algs(self, algs):\n",
    "        \"\"\"\n",
    "        :param algs: e.g., )'MiniBatchKMeans'\n",
    "                            'AffinityPropagation'\n",
    "                            'MeanShift'\n",
    "                            'SpectralClustering'\n",
    "                            'Ward'\n",
    "                            'AgglomerativeClustering'\n",
    "                            'DBSCAN'\n",
    "                            'OPTICS'\n",
    "                            'Birch'\n",
    "                            'GaussianMixture'\n",
    "                            'OneDGaussianKernel'\n",
    "        \"\"\"\n",
    "        self.selected_clustering_algorithms.append(algs)\n",
    "\n",
    "    def set_data(self, X_data, y_data, clustering_variables):\n",
    "        # data that was assigned as clustering_variables are used for clustering\n",
    "        self.clustering_variables = clustering_variables\n",
    "\n",
    "        self.X_data_all = X_data\n",
    "\n",
    "        X_clustring_data = X_data[clustering_variables]\n",
    "        y_clustring_data = y_data\n",
    "\n",
    "        data_cl = (  # First data set\n",
    "                        (  # X predictors [X1, X2]\n",
    "                            # e.g., ) np.array([[10, 20], [20, 30], [11, 11], [11, 24], [25, 36], [12, 11], [30, 20]]),\n",
    "                            X_clustring_data,\n",
    "                            # Y target [Y]\n",
    "                            # e.g., ) np.array([1, 0, 1, 1, 1, 0, 1])\n",
    "                            y_clustring_data\n",
    "                        ),\n",
    "                        {  # Algorithm Parameters\n",
    "                            # 'damping': 0.77, 'preference': -240,\n",
    "                            # 'quantile': 0.2, 'n_clusters': 2, 'min_samples': 20, 'xi': 0.25\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        self.datasets.append(data_cl)\n",
    "\n",
    "    def set_base(self, parameter):\n",
    "        n_clusters = 10\n",
    "        bandwidth = 0.05\n",
    "\n",
    "        if self.selected_clustering_algorithms[0] == 'OneDGaussianKernel' or \\\n",
    "           self.selected_clustering_algorithms[0] == 'MultiDGaussianKernel':\n",
    "            bandwidth = parameter\n",
    "        else:\n",
    "            n_clusters = parameter\n",
    "\n",
    "        self.default_base = {'quantile': .3,\n",
    "                             'eps': .3,\n",
    "                             'damping': .9,\n",
    "                             'preference': -200,\n",
    "                             'n_neighbors': 10,\n",
    "                             'n_clusters': n_clusters,\n",
    "                             'min_samples': 10,\n",
    "                             'xi': 0.05,\n",
    "                             'min_cluster_size': 0.1,\n",
    "                             'bandwidth':bandwidth}\n",
    "\n",
    "    def get_selected_clustering_alg(self):\n",
    "        return self.clustering_algorithms[self.selected_clustering_algorithms[0]]\n",
    "\n",
    "    def get_clustered_data(self, alg):\n",
    "        \"\"\"\n",
    "        This returns clustered data according to a selected algorithm\n",
    "        :param alg: a selected algorithm\n",
    "        :return: clustered data\n",
    "        \"\"\"\n",
    "\n",
    "        algorithm = self.clustering_algorithms[alg]\n",
    "        # print(self.datasets)\n",
    "        re_X_data = {}\n",
    "        for i_dataset, (dataset, algo_params) in enumerate(self.datasets):\n",
    "            X = dataset\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                for i in range(len(X.index)):\n",
    "                    data_id = algorithm.labels_[i]\n",
    "                    if data_id not in re_X_data:\n",
    "                        re_X_data[data_id] = X.iloc[i].transpose()\n",
    "                    else:\n",
    "                        re_X_data[data_id] = pd.concat((re_X_data[data_id], X.iloc[i]), axis=1)\n",
    "\n",
    "                for key in re_X_data:\n",
    "                    re_X_data[key] = re_X_data[key].transpose()\n",
    "\n",
    "            elif not isinstance(X, pd.DataFrame):\n",
    "                for i in range(len(X)):\n",
    "                    data_id = algorithm.labels_[i]\n",
    "                    if data_id not in re_X_data:\n",
    "                        re_X_data[data_id] = np.array([X[i]])\n",
    "                    else:\n",
    "                        re_X_data[data_id] = np.concatenate((re_X_data[data_id], [X[i]]), axis=0)\n",
    "\n",
    "            return re_X_data\n",
    "\n",
    "    def get_clustered_data_XY(self, alg):\n",
    "        \"\"\"\n",
    "        This returns clustered data according to a selected algorithm\n",
    "        :param alg: a selected algorithm\n",
    "        :return: clustered data\n",
    "        \"\"\"\n",
    "\n",
    "        algorithm = self.clustering_algorithms[alg]\n",
    "        # print(self.datasets)\n",
    "        re_X_data = {}\n",
    "        re_y_data = {}\n",
    "        re_data = {}\n",
    "        for i_dataset, (dataset, algo_params) in enumerate(self.datasets):\n",
    "            X, y = dataset\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                for i in range(len(X.index)):\n",
    "                    data_id = algorithm.labels_[i]\n",
    "                    if data_id not in re_X_data:\n",
    "                        re_X_data[data_id] = self.X_data_all.iloc[i].transpose()\n",
    "                        re_y_data[data_id] = y.iloc[i]\n",
    "                        re_data[data_id] = pd.concat([self.X_data_all.iloc[i], y.iloc[i]], axis=0)\n",
    "                    else:\n",
    "                        re_X_data[data_id] = pd.concat((re_X_data[data_id], self.X_data_all.iloc[i]), axis=1)\n",
    "                        re_y_data[data_id] = pd.concat((re_y_data[data_id], y.iloc[i]), axis=1)\n",
    "                        re_data[data_id] = pd.concat((re_X_data[data_id], re_y_data[data_id]), axis=0)\n",
    "\n",
    "                for key in re_X_data:\n",
    "                    re_X_data[key] = re_X_data[key].transpose()\n",
    "                    re_y_data[key] = re_y_data[key].transpose()\n",
    "                    re_data[key] = re_data[key].transpose()\n",
    "\n",
    "            elif not isinstance(X, pd.DataFrame):\n",
    "                for i in range(len(X)):\n",
    "                    data_id = algorithm.labels_[i]\n",
    "                    if data_id not in re_X_data:\n",
    "                        re_X_data[data_id] = np.array([self.X_data_all[i]])\n",
    "                        re_y_data[data_id] = np.array([y[i]])\n",
    "                        re_data[data_id] = np.concatenate((re_X_data[data_id], re_y_data[data_id]), axis=1)\n",
    "                    else:\n",
    "                        re_X_data[data_id] = np.concatenate((re_X_data[data_id], [self.X_data_all[i]]), axis=0)\n",
    "                        re_y_data[data_id] = np.concatenate((re_y_data[data_id], [y[i]]), axis=0)\n",
    "                        re_data[data_id] = np.concatenate((re_X_data[data_id], re_y_data[data_id]), axis=1)\n",
    "\n",
    "            return re_data, re_X_data, re_y_data\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        for i_dataset, (dataset, algo_params) in enumerate(self.datasets):\n",
    "            # update parameters with dataset-specific values\n",
    "            params = self.default_base.copy()\n",
    "            params.update(algo_params)\n",
    "\n",
    "            X, y = dataset\n",
    "\n",
    "            # normalize dataset for easier parameter selection\n",
    "            X = self.scaler.fit_transform(X)\n",
    "\n",
    "            print(f'mean{self.scaler.mean_}, var{self.scaler.var_}, n_samples[{self.scaler.n_samples_seen_}], scale[{self.scaler.scale_}]')\n",
    "\n",
    "            # estimate bandwidth for mean shift\n",
    "            bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n",
    "\n",
    "            # connectivity matrix for structured Ward\n",
    "            connectivity = kneighbors_graph(X, n_neighbors=params['n_neighbors'], include_self=False)\n",
    "\n",
    "            # make connectivity symmetric\n",
    "            connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "            # ============\n",
    "            # Create cluster objects\n",
    "            # ============\n",
    "            for alg in self.selected_clustering_algorithms:\n",
    "                if alg is 'MiniBatchKMeans':\n",
    "                    self.clustering_algorithms['MiniBatchKMeans'] = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n",
    "                elif alg is 'AffinityPropagation':\n",
    "                    self.clustering_algorithms['AffinityPropagation'] = cluster.AffinityPropagation(damping=params['damping'],preference=params['preference'])\n",
    "                elif alg is 'MeanShift':\n",
    "                    self.clustering_algorithms['MeanShift'] = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "                elif alg is 'SpectralClustering':\n",
    "                    self.clustering_algorithms['SpectralClustering'] = cluster.SpectralClustering(n_clusters=params['n_clusters'], eigen_solver='arpack', affinity=\"nearest_neighbors\")\n",
    "                elif alg is 'Ward':\n",
    "                    self.clustering_algorithms['Ward'] = cluster.AgglomerativeClustering(n_clusters=params['n_clusters'], linkage='ward', connectivity=connectivity)\n",
    "                elif alg is 'AgglomerativeClustering':\n",
    "                    self.clustering_algorithms['AgglomerativeClustering'] = cluster.AgglomerativeClustering(linkage=\"average\", affinity=\"cityblock\", n_clusters=params['n_clusters'], connectivity=connectivity)\n",
    "                elif alg is 'DBSCAN':\n",
    "                    self.clustering_algorithms['DBSCAN'] = cluster.DBSCAN(eps=params['eps'])\n",
    "                elif alg is 'OPTICS':\n",
    "                    self.clustering_algorithms['OPTICS'] = cluster.OPTICS(min_samples=params['min_samples'], xi=params['xi'], min_cluster_size=params['min_cluster_size'])\n",
    "                elif alg is 'Birch':\n",
    "                    self.clustering_algorithms['Birch'] = cluster.Birch(n_clusters=params['n_clusters'])\n",
    "                elif alg is 'GaussianMixture':\n",
    "                    self.clustering_algorithms['GaussianMixture'] = mixture.GaussianMixture(n_components=params['n_clusters'], covariance_type='full')\n",
    "                elif alg is 'OneDGaussianKernel':\n",
    "                    self.clustering_algorithms['OneDGaussianKernel'] = OneDimensionalGaussianKernel(bandwidth=params['bandwidth'])\n",
    "                elif alg is 'MultiDGaussianKernel':\n",
    "                    self.clustering_algorithms['MultiDGaussianKernel'] = MultiDimensionalGaussianKernel(bandwidth=params['bandwidth'])\n",
    "\n",
    "\n",
    "            # self.clustering_algorithms['MiniBatchKMeans'] = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n",
    "            # self.clustering_algorithms['AffinityPropagation'] = cluster.AffinityPropagation(damping=params['damping'], preference=params['preference'])\n",
    "            # self.clustering_algorithms['MeanShift'] = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "            # self.clustering_algorithms['SpectralClustering'] = cluster.SpectralClustering(n_clusters=params['n_clusters'], eigen_solver='arpack', affinity=\"nearest_neighbors\")\n",
    "            # self.clustering_algorithms['Ward'] = cluster.AgglomerativeClustering(n_clusters=params['n_clusters'], linkage='ward', connectivity=connectivity)\n",
    "            # self.clustering_algorithms['AgglomerativeClustering'] = cluster.AgglomerativeClustering(linkage=\"average\", affinity=\"cityblock\", n_clusters=params['n_clusters'], connectivity=connectivity)\n",
    "            # self.clustering_algorithms['DBSCAN'] = cluster.DBSCAN(eps=params['eps'])\n",
    "            # self.clustering_algorithms['OPTICS'] = cluster.OPTICS(min_samples=params['min_samples'], xi=params['xi'], min_cluster_size=params['min_cluster_size'])\n",
    "            # self.clustering_algorithms['Birch'] = cluster.Birch(n_clusters=params['n_clusters'])\n",
    "            # self.clustering_algorithms['GaussianMixture'] = mixture.GaussianMixture(n_components=params['n_clusters'], covariance_type='full')\n",
    "\n",
    "            for name, algorithm in self.clustering_algorithms.items():\n",
    "                t0 = time.time()\n",
    "\n",
    "                # catch warnings related to kneighbors_graph\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\n",
    "                        \"ignore\",\n",
    "                        message=\"the number of connected components of the \" +\n",
    "                        \"connectivity matrix is [0-9]{1,2}\" +\n",
    "                        \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "                        category=UserWarning)\n",
    "                    warnings.filterwarnings(\n",
    "                        \"ignore\",\n",
    "                        message=\"Graph is not fully connected, spectral embedding\" +\n",
    "                        \" may not work as expected.\",\n",
    "                        category=UserWarning)\n",
    "                    algorithm.fit(X)\n",
    "\n",
    "                t1 = time.time()\n",
    "                if hasattr(algorithm, 'labels_'):\n",
    "                    y_pred = algorithm.labels_.astype(np.int)\n",
    "                else:\n",
    "                    y_pred = algorithm.predict(X)\n",
    "                    algorithm.labels_ = y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
